Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 30
Rules claiming more threads will be scaled down.
Job stats:
job             count    min threads    max threads
------------  -------  -------------  -------------
all                 1              1              1
dedup_normal        7             10             10
quantify            1             10             10
total               9              1             10

Select jobs to execute...

[Wed May 22 14:09:24 2024]
rule dedup_normal:
    input: output/PnG_1/PnG_1.bam
    output: output/PnG_1/Norm_dedup_PnG_1.bam
    log: logs/PnG_1/Norm_dedup.log
    jobid: 95
    reason: Missing output files: output/PnG_1/Norm_dedup_PnG_1.bam
    wildcards: sample=PnG_1
    threads: 10
    resources: tmpdir=/tmp, mem_gb=50


[Wed May 22 14:09:24 2024]
rule dedup_normal:
    input: output/Lys_2/Lys_2.bam
    output: output/Lys_2/Norm_dedup_Lys_2.bam
    log: logs/Lys_2/Norm_dedup.log
    jobid: 98
    reason: Missing output files: output/Lys_2/Norm_dedup_Lys_2.bam
    wildcards: sample=Lys_2
    threads: 10
    resources: tmpdir=/tmp, mem_gb=50


[Wed May 22 14:09:24 2024]
rule dedup_normal:
    input: output/FivePoints_1/FivePoints_1.bam
    output: output/FivePoints_1/Norm_dedup_FivePoints_1.bam
    log: logs/FivePoints_1/Norm_dedup.log
    jobid: 99
    reason: Missing output files: output/FivePoints_1/Norm_dedup_FivePoints_1.bam
    wildcards: sample=FivePoints_1
    threads: 10
    resources: tmpdir=/tmp, mem_gb=50

[Wed May 22 14:34:02 2024]
Finished job 98.
1 of 9 steps (11%) done
Select jobs to execute...

[Wed May 22 14:34:02 2024]
rule dedup_normal:
    input: output/PnG_2/PnG_2.bam
    output: output/PnG_2/Norm_dedup_PnG_2.bam
    log: logs/PnG_2/Norm_dedup.log
    jobid: 96
    reason: Missing output files: output/PnG_2/Norm_dedup_PnG_2.bam
    wildcards: sample=PnG_2
    threads: 10
    resources: tmpdir=/tmp, mem_gb=50

[Wed May 22 14:34:40 2024]
Finished job 95.
2 of 9 steps (22%) done
Select jobs to execute...

[Wed May 22 14:34:40 2024]
rule dedup_normal:
    input: output/Control_2/Control_2.bam
    output: output/Control_2/Norm_dedup_Control_2.bam
    log: logs/Control_2/Norm_dedup.log
    jobid: 94
    reason: Missing output files: output/Control_2/Norm_dedup_Control_2.bam
    wildcards: sample=Control_2
    threads: 10
    resources: tmpdir=/tmp, mem_gb=50

[Wed May 22 14:38:14 2024]
Finished job 99.
3 of 9 steps (33%) done
Select jobs to execute...

[Wed May 22 14:38:14 2024]
rule dedup_normal:
    input: output/Control_1/Control_1.bam
    output: output/Control_1/Norm_dedup_Control_1.bam
    log: logs/Control_1/Norm_dedup.log
    jobid: 93
    reason: Missing output files: output/Control_1/Norm_dedup_Control_1.bam
    wildcards: sample=Control_1
    threads: 10
    resources: tmpdir=/tmp, mem_gb=50

[Wed May 22 14:57:37 2024]
Finished job 93.
4 of 9 steps (44%) done
Select jobs to execute...

[Wed May 22 14:57:37 2024]
rule dedup_normal:
    input: output/Lys_1/Lys_1.bam
    output: output/Lys_1/Norm_dedup_Lys_1.bam
    log: logs/Lys_1/Norm_dedup.log
    jobid: 97
    reason: Missing output files: output/Lys_1/Norm_dedup_Lys_1.bam
    wildcards: sample=Lys_1
    threads: 10
    resources: tmpdir=/tmp, mem_gb=50

[Wed May 22 14:58:51 2024]
Finished job 94.
5 of 9 steps (56%) done
[Wed May 22 15:00:24 2024]
Finished job 96.
6 of 9 steps (67%) done
[Wed May 22 15:14:57 2024]
Finished job 97.
7 of 9 steps (78%) done
Select jobs to execute...

[Wed May 22 15:14:57 2024]
rule quantify:
    input: output/Control_1/Norm_dedup_Control_1.bam, output/Control_2/Norm_dedup_Control_2.bam, output/PnG_1/Norm_dedup_PnG_1.bam, output/PnG_2/Norm_dedup_PnG_2.bam, output/Lys_1/Norm_dedup_Lys_1.bam, output/Lys_2/Norm_dedup_Lys_2.bam, output/FivePoints_1/Norm_dedup_FivePoints_1.bam
    output: output/counts.txt
    log: logs/featureCounts.log
    jobid: 92
    reason: Missing output files: output/counts.txt; Input files updated by another job: output/PnG_1/Norm_dedup_PnG_1.bam, output/FivePoints_1/Norm_dedup_FivePoints_1.bam, output/Lys_2/Norm_dedup_Lys_2.bam, output/Lys_1/Norm_dedup_Lys_1.bam, output/PnG_2/Norm_dedup_PnG_2.bam, output/Control_2/Norm_dedup_Control_2.bam, output/Control_1/Norm_dedup_Control_1.bam
    threads: 10
    resources: tmpdir=/tmp, mem_gb=50

[Wed May 22 15:14:57 2024]
Error in rule quantify:
    jobid: 92
    input: output/Control_1/Norm_dedup_Control_1.bam, output/Control_2/Norm_dedup_Control_2.bam, output/PnG_1/Norm_dedup_PnG_1.bam, output/PnG_2/Norm_dedup_PnG_2.bam, output/Lys_1/Norm_dedup_Lys_1.bam, output/Lys_2/Norm_dedup_Lys_2.bam, output/FivePoints_1/Norm_dedup_FivePoints_1.bam
    output: output/counts.txt
    log: logs/featureCounts.log (check log file(s) for error details)
    shell:
        
        /mnt/store/DMTS/common_programs/subread-2.0.6-Linux-x86_64/bin/featureCounts -t sRNA -g ID -F GTF -M --fraction -s 1 -p --countReadPairs -T 10 -a /scratch/kotryna/Giedrius/2016_sRNALactis/output/code/FinalsRNRList/sRNA.gff3 -o output/counts.txt 
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: ../../../../../scratch/kotryna/Giedrius/2016_sRNALactis/data_prep/.snakemake/log/2024-05-22T140923.663327.snakemake.log
